# SSFG: Stochastically Scaling Features and Gradients for Regularizing Graph Convolutional Networks
<br>

In this repository,  we implement the SSFG (stochastic ReLU) regularization method for regularizing graph convoultional networks. Our paper "SSFG: Stochastically Scaling Features and Gradients for Regularizing Graph Convolutional Networks" is available on Arxiv at [https://arxiv.org/abs/2102.10338](https://arxiv.org/abs/2102.10338).

```
@article{zhang2021ssfg,
  title={SSFG: Stochastically Scaling Features and Gradients for Regularizing Graph Convolution Networks},
  author={Zhang, Haimin and Xu, Min},
  journal={arXiv preprint arXiv:2102.10338},
  year={2021}
}
```

### Preparation

Install PyTorch and the benchmark datasets following the official [Benchmarking Graph Neural Networks](https://github.com/graphdeeplearning/benchmarking-gnns).
